% Analyze Attention Detection Results
% This script helps you interpret the .mat files generated by the attention detection analysis

function analyze_attention_results()
% ANALYZE_ATTENTION_RESULTS Comprehensive analysis of attention detection .mat files

fprintf('=== Attention Detection Results Analysis ===\n\n');

%% Step 1: Load and analyze attention results files
fprintf('📊 STEP 1: Loading attention detection results...\n');
fprintf('%s\n', repmat('=', 1, 50));

% Find all attention results files
methods = {'correlation', 'trf', 'cca'};
results_data = struct();

for i = 1:length(methods)
    method = methods{i};
    filename = sprintf('attention_results_%s.mat', method);
    
    if exist(filename, 'file')
        fprintf('✅ Loading: %s\n', filename);
        loaded = load(filename);
        results_data.(method) = loaded.attention_results;
        
        % Display basic info
        num_trials = results_data.(method).num_trials;
        predictions = results_data.(method).predictions;
        confidence = results_data.(method).confidence;
        
        fprintf('   Method: %s\n', method);
        fprintf('   Trials: %d\n', num_trials);
        fprintf('   Left attention: %d trials (%.1f%%)\n', ...
                sum(predictions == 1), sum(predictions == 1)/num_trials*100);
        fprintf('   Right attention: %d trials (%.1f%%)\n', ...
                sum(predictions == 2), sum(predictions == 2)/num_trials*100);
        fprintf('   Mean confidence: %.3f (range: %.3f to %.3f)\n\n', ...
                mean(confidence), min(confidence), max(confidence));
    else
        fprintf('❌ Not found: %s\n', filename);
    end
end

%% Step 2: Load and analyze validation results
fprintf('🔍 STEP 2: Loading validation results...\n');
fprintf('%s\n', repmat('=', 1, 50));

validation_filename = 'validation_results_correlation.mat';
if exist(validation_filename, 'file')
    fprintf('✅ Loading: %s\n', validation_filename);
    loaded_val = load(validation_filename);
    validation_data = loaded_val.validation_results;
    
    fprintf('   Method: %s\n', validation_data.method);
    if ~isnan(validation_data.accuracy)
        fprintf('   Overall Accuracy: %.1f%%\n', validation_data.accuracy * 100);
        
        % Interpret accuracy
        if validation_data.accuracy > 0.7
            fprintf('   Performance: 🟢 EXCELLENT (>70%%)\n');
        elseif validation_data.accuracy > 0.6
            fprintf('   Performance: 🟡 GOOD (60-70%%)\n');
        elseif validation_data.accuracy > 0.5
            fprintf('   Performance: 🟠 MODERATE (50-60%%)\n');
        else
            fprintf('   Performance: 🔴 POOR (<50%%, below chance)\n');
        end
    else
        fprintf('   Accuracy: N/A (no ground truth available)\n');
        fprintf('   Performance: ⚪ UNKNOWN (need labeled data for validation)\n');
    end
    
    fprintf('   Confidence stats: Mean=%.3f, Std=%.3f\n', ...
            validation_data.confidence_stats.mean, ...
            validation_data.confidence_stats.std);
    
    if ~isempty(validation_data.cross_validation) && ~any(isnan(validation_data.cross_validation))
        fprintf('   Cross-validation: %.1f%% ± %.1f%%\n', ...
                mean(validation_data.cross_validation) * 100, ...
                std(validation_data.cross_validation) * 100);
    end
    
else
    fprintf('❌ Not found: %s\n', validation_filename);
end

%% Step 3: Detailed analysis of each method
fprintf('\n📈 STEP 3: Detailed method comparison...\n');
fprintf('%s\n', repmat('=', 1, 50));

method_names = fieldnames(results_data);
if ~isempty(method_names)
    
    % Create comparison table
    fprintf('Method Comparison:\n');
    fprintf('%-12s | %-8s | %-8s | %-12s | %-12s\n', 'Method', 'Left%', 'Right%', 'Mean Conf', 'Consistency');
    fprintf('%s\n', repmat('-', 1, 60));
    
    all_predictions = {};
    prediction_lengths = [];
    
    for i = 1:length(method_names)
        method = method_names{i};
        data = results_data.(method);
        
        left_pct = sum(data.predictions == 1) / data.num_trials * 100;
        right_pct = sum(data.predictions == 2) / data.num_trials * 100;
        mean_conf = mean(data.confidence);
        
        % Calculate consistency (how often predictions are high confidence)
        high_conf_threshold = mean(data.confidence) + 0.5 * std(data.confidence);
        consistency = sum(data.confidence > high_conf_threshold) / length(data.confidence) * 100;
        
        fprintf('%-12s | %7.1f%% | %7.1f%% | %11.3f | %11.1f%%\n', ...
                method, left_pct, right_pct, mean_conf, consistency);
        
        % Store predictions in cell array to handle different lengths
        all_predictions{i} = data.predictions(:)';
        prediction_lengths(i) = length(data.predictions);
    end
    
    % Method agreement analysis (only if all methods have same number of trials)
    if length(unique(prediction_lengths)) == 1 && length(method_names) > 1
        fprintf('\nMethod Agreement Analysis:\n');
        agreement_matrix = zeros(length(method_names), length(method_names));
        
        for i = 1:length(method_names)
            for j = 1:length(method_names)
                if i ~= j
                    agreement = mean(all_predictions{i} == all_predictions{j}) * 100;
                    agreement_matrix(i, j) = agreement;
                end
            end
        end
        
        fprintf('Agreement between methods (percentage):\n');
        fprintf('%-12s', '');
        for j = 1:length(method_names)
            fprintf(' | %-10s', method_names{j});
        end
        fprintf('\n');
        
        for i = 1:length(method_names)
            fprintf('%-12s', method_names{i});
            for j = 1:length(method_names)
                if i == j
                    fprintf(' | %10s', '---');
                else
                    fprintf(' | %9.1f%%', agreement_matrix(i, j));
                end
            end
            fprintf('\n');
        end
    elseif length(method_names) > 1
        fprintf('\nMethod Agreement Analysis:\n');
        fprintf('Cannot compare methods - different number of trials:\n');
        for i = 1:length(method_names)
            fprintf('• %s: %d trials\n', method_names{i}, prediction_lengths(i));
        end
    end
end

%% Step 4: Trial-by-trial analysis
fprintf('\n🔬 STEP 4: Trial-by-trial detailed analysis...\n');
fprintf('%s\n', repmat('=', 1, 50));

if ~isempty(method_names)
    % Use the first method for detailed analysis (typically correlation)
    primary_method = method_names{1};
    primary_data = results_data.(primary_method);
    
    fprintf('Detailed analysis using %s method:\n\n', primary_method);
    
    % Sort trials by confidence
    [sorted_conf, sort_idx] = sort(primary_data.confidence, 'descend');
    sorted_pred = primary_data.predictions(sort_idx);
    
    fprintf('Trial-by-trial results (sorted by confidence):\n');
    fprintf('%-5s | %-10s | %-10s | %-15s\n', 'Trial', 'Prediction', 'Confidence', 'Interpretation');
    fprintf('%s\n', repmat('-', 1, 50));
    
    for i = 1:length(sorted_conf)
        trial_num = sort_idx(i);
        pred_str = sprintf('%s ear', iif(sorted_pred(i) == 1, 'Left', 'Right'));
        conf_val = sorted_conf(i);
        
        % Interpretation based on confidence
        if conf_val > mean(primary_data.confidence) + std(primary_data.confidence)
            interpretation = 'High confidence';
        elseif conf_val > mean(primary_data.confidence)
            interpretation = 'Above average';
        elseif conf_val > mean(primary_data.confidence) - std(primary_data.confidence)
            interpretation = 'Below average';
        else
            interpretation = 'Low confidence';
        end
        
        fprintf('%5d | %-10s | %10.3f | %-15s\n', trial_num, pred_str, conf_val, interpretation);
        
        % Only show first 10 trials to avoid clutter
        if i >= 10
            fprintf('... (showing top 10 trials)\n');
            break;
        end
    end
end

%% Step 5: Statistical analysis
fprintf('\n📊 STEP 5: Statistical analysis...\n');
fprintf('%s\n', repmat('=', 1, 50));

if ~isempty(method_names)
    primary_data = results_data.(method_names{1});
    
    % Basic statistics
    fprintf('Statistical Summary:\n');
    fprintf('• Total trials: %d\n', primary_data.num_trials);
    fprintf('• Left ear predictions: %d (%.1f%%)\n', ...
            sum(primary_data.predictions == 1), ...
            sum(primary_data.predictions == 1)/primary_data.num_trials*100);
    fprintf('• Right ear predictions: %d (%.1f%%)\n', ...
            sum(primary_data.predictions == 2), ...
            sum(primary_data.predictions == 2)/primary_data.num_trials*100);
    
    % Confidence statistics
    fprintf('\nConfidence Analysis:\n');
    fprintf('• Mean: %.3f\n', mean(primary_data.confidence));
    fprintf('• Median: %.3f\n', median(primary_data.confidence));
    fprintf('• Standard deviation: %.3f\n', std(primary_data.confidence));
    fprintf('• Range: [%.3f, %.3f]\n', min(primary_data.confidence), max(primary_data.confidence));
    
    % Distribution analysis
    fprintf('\nDistribution Analysis:\n');
    conf_quartiles = prctile(primary_data.confidence, [25, 50, 75]);
    fprintf('• 25th percentile: %.3f\n', conf_quartiles(1));
    fprintf('• 50th percentile (median): %.3f\n', conf_quartiles(2));
    fprintf('• 75th percentile: %.3f\n', conf_quartiles(3));
    
    % Bias analysis
    left_conf = primary_data.confidence(primary_data.predictions == 1);
    right_conf = primary_data.confidence(primary_data.predictions == 2);
    
    if ~isempty(left_conf) && ~isempty(right_conf)
        fprintf('\nBias Analysis:\n');
        fprintf('• Left ear mean confidence: %.3f\n', mean(left_conf));
        fprintf('• Right ear mean confidence: %.3f\n', mean(right_conf));
        
        [~, p_val] = ttest2(left_conf, right_conf);
        fprintf('• Confidence difference p-value: %.3f', p_val);
        if p_val < 0.05
            fprintf(' (significant difference)\n');
        else
            fprintf(' (no significant difference)\n');
        end
    end
end

%% Step 6: Recommendations
fprintf('\n💡 STEP 6: Recommendations and next steps...\n');
fprintf('%s\n', repmat('=', 1, 50));

fprintf('Based on your results:\n\n');

% Performance-based recommendations
if exist('validation_data', 'var') && ~isnan(validation_data.accuracy)
    accuracy = validation_data.accuracy;
    
    if accuracy > 0.7
        fprintf('🟢 EXCELLENT PERFORMANCE:\n');
        fprintf('   • Your algorithm is working very well!\n');
        fprintf('   • Consider testing on more subjects\n');
        fprintf('   • Try real-time implementation\n');
        fprintf('   • Publish your results\n\n');
        
    elseif accuracy > 0.6
        fprintf('🟡 GOOD PERFORMANCE:\n');
        fprintf('   • Algorithm shows promise\n');
        fprintf('   • Try parameter optimization\n');
        fprintf('   • Consider ensemble methods\n');
        fprintf('   • Test on more data\n\n');
        
    elseif accuracy > 0.5
        fprintf('🟠 MODERATE PERFORMANCE:\n');
        fprintf('   • Algorithm needs improvement\n');
        fprintf('   • Check data preprocessing\n');
        fprintf('   • Try different methods (TRF, CCA)\n');
        fprintf('   • Verify ground truth labels\n\n');
        
    else
        fprintf('🔴 POOR PERFORMANCE:\n');
        fprintf('   • Algorithm performing below chance\n');
        fprintf('   • Check data quality and preprocessing\n');
        fprintf('   • Verify experimental paradigm\n');
        fprintf('   • Consider different approaches\n\n');
    end
else
    fprintf('⚪ PERFORMANCE UNKNOWN:\n');
    fprintf('   • No ground truth available for validation\n');
    fprintf('   • Check if your data has attention labels\n');
    fprintf('   • Consider manual annotation of some trials\n');
    fprintf('   • Use behavioral data if available\n\n');
end

% Method-specific recommendations
if ~isempty(method_names)
    fprintf('Method-specific insights:\n');
    
    for i = 1:length(method_names)
        method = method_names{i};
        data = results_data.(method);
        mean_conf = mean(data.confidence);
        
        fprintf('• %s method: ', upper(method));
        if mean_conf > 0.1
            fprintf('High confidence predictions\n');
        elseif mean_conf > 0.05
            fprintf('Moderate confidence predictions\n');
        else
            fprintf('Low confidence predictions - may need tuning\n');
        end
    end
end

fprintf('\nNext steps:\n');
fprintf('1. Examine the visualization files (trial_X_visualization.png)\n');
fprintf('2. Look at validation plots (validation_plots_*.png)\n');
fprintf('3. Process additional subjects for robust validation\n');
fprintf('4. Consider implementing real-time attention detection\n');
fprintf('5. Optimize parameters based on these results\n\n');

% Save detailed analysis
analysis_summary = struct();
analysis_summary.results_data = results_data;
if exist('validation_data', 'var')
    analysis_summary.validation_data = validation_data;
end
analysis_summary.analysis_timestamp = datestr(now);

save('detailed_analysis_summary.mat', 'analysis_summary');
fprintf('📁 Detailed analysis saved to: detailed_analysis_summary.mat\n\n');

fprintf('🎉 ANALYSIS COMPLETE!\n');
fprintf('Review the insights above and examine the visualization files.\n\n');

end

function result = iif(condition, true_val, false_val)
if condition
    result = true_val;
else
    result = false_val;
end
end